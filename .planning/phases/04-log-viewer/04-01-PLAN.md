---
phase: 04-log-viewer
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src-tauri/src/commands/logs.rs
  - src-tauri/src/commands/mod.rs
  - src-tauri/src/lib.rs
autonomous: true
must_haves:
  truths:
    - "Backend can stream stdout from Docker containers"
    - "Backend can stream stderr from Docker containers"
    - "Frontend can receive log events via Channel"
  artifacts:
    - path: "src-tauri/src/commands/logs.rs"
      provides: "Log streaming command and LogEvent enum"
      exports: ["stream_container_logs", "LogEvent"]
      contains: "pub enum LogEvent"
    - path: "src-tauri/src/commands/mod.rs"
      provides: "Module registration"
      contains: "pub mod logs"
    - path: "src-tauri/src/lib.rs"
      provides: "Command registration"
      contains: "commands::logs::stream_container_logs"
  key_links:
    - from: "src-tauri/src/commands/logs.rs"
      to: "bollard::Docker"
      via: "docker.logs() with LogsOptionsBuilder"
      pattern: "docker\\.logs"
    - from: "src-tauri/src/commands/logs.rs"
      to: "Frontend"
      via: "tauri::ipc::Channel<LogEvent>"
      pattern: "Channel<LogEvent>"
---

<objective>
Create backend log streaming infrastructure using bollard's Docker logs API and Tauri's IPC Channel for real-time streaming to frontend.

Purpose: Enable real-time container log streaming from Docker to the Svelte frontend.
Output: Working `stream_container_logs` command that emits LogEvent via Channel.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-log-viewer/04-RESEARCH.md

# Existing patterns to follow
@src-tauri/src/commands/instances.rs
@src-tauri/src/commands/mod.rs
@src-tauri/src/lib.rs
</context>

<tasks>

<task type="auto">
  <name>Create logs.rs with LogEvent enum and stream command</name>
  <files>src-tauri/src/commands/logs.rs</files>
  <action>
Create a new file `src-tauri/src/commands/logs.rs` with:

1. **LogEvent enum** (derive Clone, Serialize):
   - `StdOut { message: String }` - for stdout lines
   - `StdErr { message: String }` - for stderr lines
   - `Error { message: String }` - for stream errors
   - `Eof` - when stream ends

   Use `#[serde(tag = "type", content = "data")]` for clean JSON serialization.

2. **stream_container_logs command**:
   ```rust
   #[tauri::command]
   pub async fn stream_container_logs(
       container_name: String,
       on_log: Channel<LogEvent>,
       tail: Option<u64>,
   ) -> Result<(), String>
   ```

   Implementation:
   - Connect to Docker with `Docker::connect_with_local_defaults()`
   - Build LogsOptions with `LogsOptionsBuilder`:
     - stdout: true, stderr: true, follow: true
     - tail: tail parameter or "100" default
     - timestamps: true
   - Iterate stream with `futures::StreamExt`
   - Match on `LogOutput::StdOut` and `LogOutput::StdErr`
   - Use `String::from_utf8_lossy()` for UTF-8 safety
   - Send LogEvent::Eof when stream ends
   - Handle errors by sending LogEvent::Error then breaking

3. **Imports needed**:
   - `bollard::Docker`
   - `bollard::query_parameters::LogsOptionsBuilder`
   - `bollard::container::LogOutput`
   - `futures::StreamExt`
   - `tauri::ipc::Channel`
   - `serde::Serialize`

DO NOT add stop_log_stream command yet - keep it simple for this phase.
DO NOT use CancellationToken - stream runs until container stops or frontend disconnects.
</action>
  <verify>
# Verify file exists and compiles
test -f src-tauri/src/commands/logs.rs && echo "File created"

# Check for required patterns
grep -q "pub enum LogEvent" src-tauri/src/commands/logs.rs && echo "LogEvent enum found"
grep -q "stream_container_logs" src-tauri/src/commands/logs.rs && echo "Command found"
grep -q "Channel<LogEvent>" src-tauri/src/commands/logs.rs && echo "Channel usage found"
grep -q "from_utf8_lossy" src-tauri/src/commands/logs.rs && echo "UTF-8 safety found"

# Build to verify compilation
cd src-tauri && cargo check 2>&1 | tail -20
</verify>
  <done>
- logs.rs file exists with LogEvent enum (StdOut, StdErr, Error, Eof variants)
- stream_container_logs command uses bollard logs() with follow:true
- UTF-8 handled with from_utf8_lossy()
- Code compiles without errors
</done>
</task>

<task type="auto">
  <name>Register logs module and command</name>
  <files>
    - src-tauri/src/commands/mod.rs
    - src-tauri/src/lib.rs
  </files>
  <action>
1. **Update src-tauri/src/commands/mod.rs**:
   Add `pub mod logs;` to the existing module declarations.

2. **Update src-tauri/src/lib.rs**:
   Add `commands::logs::stream_container_logs` to the `invoke_handler` generate_handler! macro.

Follow the existing pattern used for other commands (instances, connections, etc.).
</action>
  <verify>
# Verify module registration
grep -q "pub mod logs" src-tauri/src/commands/mod.rs && echo "Module registered"

# Verify command registration
grep -q "commands::logs::stream_container_logs" src-tauri/src/lib.rs && echo "Command registered"

# Build to verify everything compiles
cd src-tauri && cargo check 2>&1 | tail -10
</verify>
  <done>
- logs module declared in mod.rs
- stream_container_logs registered in invoke_handler
- Full project compiles successfully
</done>
</task>

</tasks>

<verification>
1. `cargo check` passes in src-tauri directory
2. logs.rs contains LogEvent enum with all 4 variants
3. logs.rs contains stream_container_logs async function
4. mod.rs includes `pub mod logs`
5. lib.rs includes command in invoke_handler
</verification>

<success_criteria>
- Backend infrastructure complete for log streaming
- LogEvent enum serializes correctly for IPC
- stream_container_logs command ready for frontend consumption
- No new dependencies required (all already in Cargo.toml)
</success_criteria>

<output>
After completion, create `.planning/phases/04-log-viewer/04-01-SUMMARY.md`
</output>
